{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fetch labelled issues using data from GH Archive\n",
        "The purpose of this notebook is to use the data provided by GH Archive and format it into dataframes that we can use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download data to local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_data(partition):\n",
        "    \"\"\"\n",
        "    Download data from url and save it to filename\n",
        "    \"\"\"\n",
        "\n",
        "    url = f\"http://data.gharchive.org/{partition}.json.gz\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(f\"../data/{partition}.json.gz\", \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "    else:\n",
        "        print(f\"Failed to download data for partition {partition}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this function to get the issue_df for a particular partition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_issues_df(partition):\n",
        "    df = pd.read_json(f\"../data/{partition}.json.gz\", lines=True)\n",
        "\n",
        "    issues_events_df = df.query(\"type == 'IssuesEvent'\")\n",
        "\n",
        "    issues_df = pd.json_normalize(issues_events_df[\"payload\"])\n",
        "\n",
        "    issues_df = issues_df.filter(items=[ 'issue.id', 'issue.url', 'action', 'issue.user.login', 'issue.title', 'issue.labels', 'issue.body'])\n",
        "    issues_df[\"issue.labels\"] = issues_df[\"issue.labels\"].apply(lambda x: [label[\"name\"] for label in x])\n",
        "\n",
        "    return issues_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this function to filter the issue df by labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_df_by_label(df, label_name: str):\n",
        "    return df[df[\"issue.labels\"].apply(lambda labels: label_name in [l.lower() for l in labels])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this function to mass download files for a date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_date_data(year, month, day):\n",
        "    date = f\"{year}-{'{:02d}'.format(month)}-{'{:02d}'.format(day)}\"\n",
        "    for hour in range(24):\n",
        "        download_data(f\"{date}-{hour}\")\n",
        "\n",
        "    issues_df = pd.concat([get_issues_df(f\"{date}-{hour}\") for hour in range(24)])\n",
        "\n",
        "    issues_df.to_pickle(f\"../data/{date}-issues.pkl\")\n",
        "    # issues_df.to_csv(f\"../data/{date}-issues.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code to download data across an entire month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in range(1, 32):\n",
        "#     try:\n",
        "#         print(f\"Downloading data for 2024-05-{i}\")\n",
        "#         download_date_data(2024, 5, i)\n",
        "#     except:\n",
        "#         print(f\"Failed to download data for 2024-05-{i}\")\n",
        "\n",
        "# issues_df = pd.concat([pd.read_pickle(f\"../data/2024-05-{'{:02d}'.format(day)}-issues.pkl\") for day in range(1, 32)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate issues dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# issues_df = get_issues_df(\"2024-05-01-01\")\n",
        "issues_df = pd.read_pickle(\"../data/2024-05-issues.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count issues by label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "bug                                        189328\n",
              "status                                     178838\n",
              "enhancement                                143259\n",
              "documentation                               23865\n",
              "Mend: dependency security vulnerability     20460\n",
              "feature                                     17586\n",
              "question                                    17201\n",
              "good first issue                            16762\n",
              "stale                                       13340\n",
              "help wanted                                 12728\n",
              "migration:no-jira                           11543\n",
              "Bug                                         11049\n",
              "triage                                       7669\n",
              "kind/bug                                     7641\n",
              "type: bug                                    6387\n",
              "b2b-marketing-services                       6287\n",
              "under review                                 5841\n",
              "frontend                                     5394\n",
              "Mend: IaC violation                          5356\n",
              "state:verified_fixed                         5165\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(np.concatenate(issues_df[\"issue.labels\"].values)).value_counts().head(20)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
